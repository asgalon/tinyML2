{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "both",
        "id": "D1J15Vh_1Jih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75d5bbc1-9207-4654-8df0-e32b68f3c9a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_keras in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorflow<2.20,>=2.19 in /usr/local/lib/python3.12/dist-packages (from tf_keras) (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (26.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.1.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow<2.20,>=2.19->tf_keras) (0.5.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow<2.20,>=2.19->tf_keras) (0.46.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow<2.20,>=2.19->tf_keras) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.10.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow<2.20,>=2.19->tf_keras) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow<2.20,>=2.19->tf_keras) (0.1.2)\n",
            "Current TensorFlow version: 2.19.0 → 2.19.0\n",
            "Current TensorFlow Hub version: 0.16.1 → 0.16.1\n",
            "Current TensorFlow Datasets version: 4.9.9 → 4.9.9\n",
            "Current NumPy version: 2.0.2 → 2.0.2\n",
            "Current Protobuf version: 5.29.5 → 5.29.5\n",
            " All packages are already at the specified versions.\n"
          ]
        }
      ],
      "source": [
        "tf_version = \"2.19.0\"\n",
        "hub_version = \"0.16.1\"\n",
        "datasets_version = \"4.9.9\"\n",
        "numpy_version = \"2.0.2\"\n",
        "protobuf_version = \"5.29.5\"\n",
        "\n",
        "!pip install tf_keras\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "try:\n",
        "    import tensorflow_hub as hub\n",
        "except:\n",
        "    hub = None\n",
        "\n",
        "try:\n",
        "    import tensorflow_datasets as tfds\n",
        "except:\n",
        "    tfds = None\n",
        "\n",
        "try:\n",
        "    from google.protobuf import __version__ as curr_protobuf_version\n",
        "\n",
        "except:\n",
        "    curr_protobuf_version = None\n",
        "\n",
        "print(f\"Current TensorFlow version: {tf.__version__} → {tf_version}\")\n",
        "if hub: print(f\"Current TensorFlow Hub version: {hub.__version__} → {hub_version}\")\n",
        "if tfds: print(f\"Current TensorFlow Datasets version: {tfds.__version__} → {datasets_version}\")\n",
        "print(f\"Current NumPy version: {np.__version__} → {numpy_version}\")\n",
        "if curr_protobuf_version: print(f\"Current Protobuf version: {curr_protobuf_version} → {protobuf_version}\")\n",
        "\n",
        "# Check if versions match\n",
        "if False and ((tf.__version__ != tf_version or\n",
        "    (hub and hub.__version__ != hub_version) or\n",
        "    (tfds and tfds.__version__ != datasets_version) or\n",
        "    not np.__version__.startswith(numpy_version))):\n",
        "\n",
        "    print(f\"Current TensorFlow version: {tf.__version__} → {tf_version}\")\n",
        "    if hub: print(f\"Current TensorFlow Hub version: {hub.__version__} → {hub_version}\")\n",
        "    if tfds: print(f\"Current TensorFlow Datasets version: {tfds.__version__} → {datasets_version}\")\n",
        "    print(f\"Current NumPy version: {np.__version__} → {numpy_version}\")\n",
        "\n",
        "    # Uninstall old versions\n",
        "    !pip uninstall -y tensorflow tensorflow_hub tensorflow_datasets numpy protobuf\n",
        "\n",
        "    # Install specific versions\n",
        "    !pip install tensorflow=={tf_version} \\\n",
        "                tensorflow_hub=={hub_version} \\\n",
        "                tensorflow_datasets=={datasets_version} \\\n",
        "                numpy=={numpy_version} \\\n",
        "                protobuf=={protobuf_version}\n",
        "\n",
        "    # Prompt user to restart\n",
        "    print(\"\\n Specified versions installed successfully.\")\n",
        "    print(\" Please restart the runtime (Runtime > Restart session) and re-run the notebook.\\n\")\n",
        "else:\n",
        "    print(\" All packages are already at the specified versions.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sqNRQoc7W17k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd0aac1-6dd9-457e-ade2-3a0c84588088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23262\n",
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([32, 224, 224, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "setattr(tfds.image_classification.cats_vs_dogs, '_URL',\"https://download.microsoft.com/download/3/E/1/3E1C3F21-ECDB-4869-8368-6DEBA77B919F/kagglecatsanddogs_5340.zip\")\n",
        "\n",
        "\n",
        "def format_image(image, label):\n",
        "    image = tf.image.resize(image, (224, 224)) / 255.0\n",
        "    return  image, label\n",
        "\n",
        "\n",
        "(raw_train, raw_validation, raw_test), metadata = tfds.load(\n",
        "    'cats_vs_dogs',\n",
        "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
        "    with_info=True,\n",
        "    as_supervised=True,\n",
        ")\n",
        "\n",
        "num_examples = metadata.splits['train'].num_examples\n",
        "num_classes = metadata.features['label'].num_classes\n",
        "print(num_examples)\n",
        "print(num_classes)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "train_batches = raw_train.shuffle(num_examples // 4).map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "validation_batches = raw_validation.map(format_image).batch(BATCH_SIZE).prefetch(1)\n",
        "test_batches = raw_test.map(format_image).batch(1)\n",
        "\n",
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "\n",
        "image_batch.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "inIK227eZbgV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee6217e9-8eb8-449c-c426-0f70a194905e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4 with input size (224, 224) and output dimension 1280\n",
            "Building model with https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_6 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2260546 (8.62 MB)\n",
            "Trainable params: 2562 (10.01 KB)\n",
            "Non-trainable params: 2257984 (8.61 MB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "582/582 [==============================] - 47s 60ms/step - loss: 0.0554 - accuracy: 0.9815 - val_loss: 0.0430 - val_accuracy: 0.9854\n",
            "Epoch 2/5\n",
            "582/582 [==============================] - 37s 52ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.0394 - val_accuracy: 0.9867\n",
            "Epoch 3/5\n",
            "582/582 [==============================] - 35s 52ms/step - loss: 0.0246 - accuracy: 0.9917 - val_loss: 0.0415 - val_accuracy: 0.9867\n",
            "Epoch 4/5\n",
            "582/582 [==============================] - 36s 51ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 0.0378 - val_accuracy: 0.9884\n",
            "Epoch 5/5\n",
            "582/582 [==============================] - 35s 50ms/step - loss: 0.0193 - accuracy: 0.9930 - val_loss: 0.0398 - val_accuracy: 0.9888\n"
          ]
        }
      ],
      "source": [
        "import tf_keras\n",
        "\n",
        "module_selection = (\"mobilenet_v2\", 224, 1280)\n",
        "handle_base, pixels, FV_SIZE = module_selection\n",
        "MODULE_HANDLE =\"https://tfhub.dev/google/tf2-preview/{}/feature_vector/4\".format(handle_base)\n",
        "IMAGE_SIZE = (pixels, pixels)\n",
        "print(\"Using {} with input size {} and output dimension {}\".format(MODULE_HANDLE, IMAGE_SIZE, FV_SIZE))\n",
        "\n",
        "feature_extractor = hub.KerasLayer(MODULE_HANDLE,\n",
        "                                   output_shape=[FV_SIZE],\n",
        "                                   trainable=False)\n",
        "\n",
        "print(\"Building model with\", MODULE_HANDLE)\n",
        "\n",
        "model = tf_keras.Sequential([\n",
        "        tf_keras.layers.Input(shape=IMAGE_SIZE + (3,)),\n",
        "        feature_extractor,\n",
        "        tf_keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "EPOCHS = 5\n",
        "\n",
        "hist = model.fit(train_batches,\n",
        "                 epochs=EPOCHS,\n",
        "                 validation_data=validation_batches)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cML-V4yqtuYI"
      },
      "outputs": [],
      "source": [
        "CATS_VS_DOGS_SAVED_MODEL = \"exp_saved_model\"\n",
        "tf.saved_model.save(model, CATS_VS_DOGS_SAVED_MODEL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gButZXqZt3o4"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(CATS_VS_DOGS_SAVED_MODEL)\n",
        "\n",
        "tflite_model = converter.convert()\n",
        "tflite_models_dir = pathlib.Path(\"/tmp/\")\n",
        "\n",
        "tflite_model_file = tflite_models_dir/'model1.tflite'\n",
        "tflite_model_file.write_bytes(tflite_model)\n",
        "# This will report back the file size in bytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MsNjuPhxuDOx"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "# Load TFLite model and allocate tensors.\n",
        "tflite_model_file = '/tmp/model1.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=tflite_model_file)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "predictions = []\n",
        "\n",
        "# This will report how many iterations per second, where each\n",
        "# iteration is 100 predictions\n",
        "test_labels, test_imgs = [], []\n",
        "for img, label in tqdm(test_batches.take(100)):\n",
        "    interpreter.set_tensor(input_index, img)\n",
        "    interpreter.invoke()\n",
        "    predictions.append(interpreter.get_tensor(output_index))\n",
        "\n",
        "    test_labels.append(label.numpy()[0])\n",
        "    test_imgs.append(img)\n",
        "\n",
        "\n",
        "# This will tell you how many of the predictions were correct\n",
        "score = 0\n",
        "for item in range(0,len(predictions)):\n",
        "  prediction=np.argmax(predictions[item])\n",
        "  label = test_labels[item]\n",
        "  if prediction==label:\n",
        "    score=score+1\n",
        "\n",
        "print(\"Out of 100 predictions I got \" + str(score) + \" correct\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRgWsPmDuJEI"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Utility functions for plotting\n",
        "# Utilities for plotting\n",
        "\n",
        "class_names = ['cat', 'dog']\n",
        "\n",
        "def plot_image(i, predictions_array, true_label, img):\n",
        "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "\n",
        "    img = np.squeeze(img)\n",
        "\n",
        "    plt.imshow(img, cmap=plt.cm.binary)\n",
        "\n",
        "    predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "    if predicted_label == true_label:\n",
        "        color = 'green'\n",
        "    else:\n",
        "        color = 'red'\n",
        "\n",
        "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                         100*np.max(predictions_array),\n",
        "                                         class_names[true_label]), color=color)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TylXFi0quLEw"
      },
      "outputs": [],
      "source": [
        "\n",
        "#@title Visualize the outputs { run: \"auto\" }\n",
        "max_index = 73 #@param {type:\"slider\", min:1, max:100, step:1}\n",
        "for index in range(0,max_index):\n",
        "  plt.figure(figsize=(6,3))\n",
        "  plt.subplot(1,2,1)\n",
        "  plot_image(index, predictions, test_labels, test_imgs)\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRMm2v9t6bbj"
      },
      "source": [
        "#Further Study\n",
        "\n",
        "To learn more about post-training quantization and optimization, please check out the user guides at https://www.tensorflow.org/lite/performance/post_training_quantization"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3_3_7_Colab.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}